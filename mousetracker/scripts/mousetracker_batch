#!/usr/bin/env python
"""
Bout Analyzer.   Extracts bilateral whisking and eyeblink data from a video snippet.

Usage:
    mousetracker_batch -h | --help
    mousetracker_batch --version
    mousetracker_batch ([-i <input_file> | --input <input_file>] | --print_config) [--config <config_file>]
                 [(-o <output_file> | --output <output_file>)] [(-v | --verbose)] [--clean]

Options:
    -h --help                   Show this screen and exit.
    --version                   Display the version and exit.
    --print_config              Print the default config value and exit.
    -i --input=<input_file>     Specify the file to process.
    -o --output=<output_file>   Specify a location to store the analyzed results.
    --config=<config_file>      Specify a path to a custom config file.  See --print-config for format.
    --clean                     If existing processed videos and analysis data exist, overwrite them with new.
    -v --verbose                Display extra diagnostic information during execution.

"""
import math
import shlex
import subprocess
import sys
from importlib.machinery import SourceFileLoader
from multiprocessing import cpu_count
from os import path
from joblib import Parallel, delayed
from datetime import datetime
import cv2
import numpy as np
from attrs_utils.interop import from_docopt
from typing import List, Optional, Tuple
import attr

# Totally hacky.
MAX_CPUS = math.ceil(cpu_count() / 2)
FRAMERATE = 240
ab_path = path.join(path.dirname(path.abspath(__file__)), "analyze_bout")
ab = SourceFileLoader('analyze_bout', ab_path).load_module()


def main(inputargs: List[str]) -> int:
    args = from_docopt(docstring=__doc__, argv=inputargs)
    tic = datetime.now()
    print(f'began run: {datetime.time(tic)}')
    files = Parallel(n_jobs=MAX_CPUS)(
        delayed(extract_slice)(args.input, start, stop) for start, stop in time_slices(args.input))
    Parallel(n_jobs=MAX_CPUS)(delayed(process)(f, args.config) for f in files)
    toc = datetime.now()
    print(f'ended run: {datetime.time(toc)}\nelapsed: {toc-tic}')
    return 0


def process(splitfile: str, config) -> None:
    print(f'processing {splitfile}')
    command = f'-i \"{splitfile}\"'
    if config != None:
        command = f"{command} --config \"{config}\""
    commandstring = shlex.split(command)

    result = ab.main(commandstring)
    print(f'{splitfile} completed with return code {result}')


def extract_slice(source: str, start: float, stop: float) -> Optional[str]:
    name, ext = path.splitext(path.basename(source))
    output_name = f'{name}_{start:2.2f}_{stop:2.2f}{ext}'
    print(f'chunking {output_name}')
    commandstring = shlex.split(f'ffmpeg -i \"{source}\" -ss {start} -t {stop} \"{output_name}\"')
    commandstring = [c.replace(' ', '\ ') for c in commandstring]
    result = subprocess.run(commandstring, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    if result.returncode != 0:
        raise IOError('ffmpeg failed to run')
    else:
        return output_name


def time_slices(source: str) -> List[Tuple[np.int64, np.int64]]:
    cap = cv2.VideoCapture(source)
    framecount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration_sec = framecount / FRAMERATE
    nchunks = math.ceil(duration_sec / MAX_CPUS)
    chunk_duration = duration_sec / nchunks
    start_times = np.linspace(start=0, stop=duration_sec - chunk_duration, num=nchunks)
    stop_times = np.linspace(start=chunk_duration, stop=duration_sec, num=nchunks)
    cap.release()
    return list(zip(start_times, stop_times))


if __name__ == "__main__":
    sys.exit(main(sys.argv[1:] if len(sys.argv) > 1 else "-h"))
